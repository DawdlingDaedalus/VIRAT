{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Accuracy Measurements for Object Detection and Tracking with YOLOv8, ByteTrack, and the VIRAT Dataset"
      ],
      "metadata": {
        "id": "vdHb8dkvPlTj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## First, obtain sample video from dataset for inference"
      ],
      "metadata": {
        "id": "9acMuDyZPtaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "ddSYXYWhlO3p"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnDM1NLKPc5l",
        "outputId": "1c0c3c38-5983-4ebf-d075-6a41edf4d414"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1C-HPOEIdZnJm_RSbYGXH6gMLhlmobaxn\n",
            "To: /content/test.mp4\n",
            "100% 10.4M/10.4M [00:00<00:00, 52.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "# upload sample file: 'VIRAT_S_000200_03_000657_000899_first300.mp4'\n",
        "# this is the first 300 frames of 'VIRAT_S_000200_03_000657_000899.mp4'\n",
        "\n",
        "!gdown \"https://drive.google.com/uc?id=1C-HPOEIdZnJm_RSbYGXH6gMLhlmobaxn\" -O test.mp4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used `ffmpeg -i VIRAT_S_000200_03_000657_000899.mp4 -c:v copy -frames:v 300 -r 30 -an ~/Desktop/VIRAT_S_000200_03_000657_000899_first300.mp4     \n",
        "`"
      ],
      "metadata": {
        "id": "zeztp189a-iH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# display details of clip\n",
        "!ffprobe -v quiet -print_format json -show_format -show_streams test.mp4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Yy8omdXfW-F",
        "outputId": "254b1019-6c65-4114-a2fd-54934e50e97e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"streams\": [\n",
            "        {\n",
            "            \"index\": 0,\n",
            "            \"codec_name\": \"mpeg4\",\n",
            "            \"codec_long_name\": \"MPEG-4 part 2\",\n",
            "            \"profile\": \"Simple Profile\",\n",
            "            \"codec_type\": \"video\",\n",
            "            \"codec_time_base\": \"1/30\",\n",
            "            \"codec_tag_string\": \"mp4v\",\n",
            "            \"codec_tag\": \"0x7634706d\",\n",
            "            \"width\": 1280,\n",
            "            \"height\": 720,\n",
            "            \"coded_width\": 1280,\n",
            "            \"coded_height\": 720,\n",
            "            \"has_b_frames\": 0,\n",
            "            \"sample_aspect_ratio\": \"1:1\",\n",
            "            \"display_aspect_ratio\": \"16:9\",\n",
            "            \"pix_fmt\": \"yuv420p\",\n",
            "            \"level\": 3,\n",
            "            \"color_range\": \"tv\",\n",
            "            \"color_space\": \"bt709\",\n",
            "            \"color_transfer\": \"bt709\",\n",
            "            \"color_primaries\": \"bt709\",\n",
            "            \"chroma_location\": \"left\",\n",
            "            \"refs\": 1,\n",
            "            \"quarter_sample\": \"false\",\n",
            "            \"divx_packed\": \"false\",\n",
            "            \"r_frame_rate\": \"30/1\",\n",
            "            \"avg_frame_rate\": \"30/1\",\n",
            "            \"time_base\": \"1/11988\",\n",
            "            \"start_pts\": 0,\n",
            "            \"start_time\": \"0.000000\",\n",
            "            \"duration_ts\": 119880,\n",
            "            \"duration\": \"10.000000\",\n",
            "            \"bit_rate\": \"8320345\",\n",
            "            \"max_bit_rate\": \"8320345\",\n",
            "            \"nb_frames\": \"300\",\n",
            "            \"disposition\": {\n",
            "                \"default\": 1,\n",
            "                \"dub\": 0,\n",
            "                \"original\": 0,\n",
            "                \"comment\": 0,\n",
            "                \"lyrics\": 0,\n",
            "                \"karaoke\": 0,\n",
            "                \"forced\": 0,\n",
            "                \"hearing_impaired\": 0,\n",
            "                \"visual_impaired\": 0,\n",
            "                \"clean_effects\": 0,\n",
            "                \"attached_pic\": 0,\n",
            "                \"timed_thumbnails\": 0\n",
            "            },\n",
            "            \"tags\": {\n",
            "                \"language\": \"und\",\n",
            "                \"handler_name\": \"VideoHandler\"\n",
            "            }\n",
            "        }\n",
            "    ],\n",
            "    \"format\": {\n",
            "        \"filename\": \"test.mp4\",\n",
            "        \"nb_streams\": 1,\n",
            "        \"nb_programs\": 0,\n",
            "        \"format_name\": \"mov,mp4,m4a,3gp,3g2,mj2\",\n",
            "        \"format_long_name\": \"QuickTime / MOV\",\n",
            "        \"start_time\": \"0.000000\",\n",
            "        \"duration\": \"10.000000\",\n",
            "        \"size\": \"10404719\",\n",
            "        \"bit_rate\": \"8323775\",\n",
            "        \"probe_score\": 100,\n",
            "        \"tags\": {\n",
            "            \"major_brand\": \"isom\",\n",
            "            \"minor_version\": \"512\",\n",
            "            \"compatible_brands\": \"isomiso2mp41\",\n",
            "            \"encoder\": \"Lavf60.3.100\"\n",
            "        }\n",
            "    }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQlBfnsdcHEd",
        "outputId": "47127ffd-4f75-4526-cc6c-7257546f0fa5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 10M\n",
            "drwxr-xr-x 1 root root 4.0K Jun 23 01:15 sample_data\n",
            "-rw-r--r-- 1 root root  10M Jun 23 18:46 test.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Secondly, obtain the ground truth bounding boxes and track IDs for this segment"
      ],
      "metadata": {
        "id": "gHXQ_jQqe_OR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VIRAT_S_000200_03_000657_000899.types.yml\n",
        "!gdown \"https://drive.google.com/uc?id=12h_35hXzoSciduBzDWmpKB2-rgUuraiN\" -O test.types.yml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEYbyKZocJWf",
        "outputId": "62f7bd83-de6c-4767-d7a4-f76ec0758107"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=12h_35hXzoSciduBzDWmpKB2-rgUuraiN\n",
            "To: /content/test.types.yml\n",
            "\r  0% 0.00/2.71k [00:00<?, ?B/s]\r100% 2.71k/2.71k [00:00<00:00, 19.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VIRAT_S_000200_03_000657_000899.regions.yml\n",
        "!gdown \"https://drive.google.com/uc?id=1Ieau47ZxLLpE6mw04XwjfANeQPB9m7hY\" -O test.regions.yml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCjlMre1cWnU",
        "outputId": "bdad18a5-9638-4ce8-a9f0-10cb6cf36889"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Ieau47ZxLLpE6mw04XwjfANeQPB9m7hY\n",
            "To: /content/test.regions.yml\n",
            "\r  0% 0.00/12.6M [00:00<?, ?B/s]\r100% 12.6M/12.6M [00:00<00:00, 142MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VIRAT_S_000200_03_000657_000899.geom.yml\n",
        "!gdown \"https://drive.google.com/uc?id=1UH9s2MPSZFdJJ7TD827DrmqGPtR_CWdQ\" -O test.geom.yml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzxAbBK9gz-K",
        "outputId": "bd09a01a-8ded-4e7d-db01-d3167ed5f44f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1UH9s2MPSZFdJJ7TD827DrmqGPtR_CWdQ\n",
            "To: /content/test.geom.yml\n",
            "\r  0% 0.00/8.54M [00:00<?, ?B/s]\r 98% 8.39M/8.54M [00:00<00:00, 83.6MB/s]\r100% 8.54M/8.54M [00:00<00:00, 84.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VIRAT_S_000200_03_000657_000899.activities.yml\n",
        "!gdown \"https://drive.google.com/uc?id=1tTAnWLE5f9FhbWCe4vElR7gD9aK0jYin\" -O test.activities.yml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ws8FiV-1hInY",
        "outputId": "511916a2-f574-4a16-b667-5894d179d5fa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1tTAnWLE5f9FhbWCe4vElR7gD9aK0jYin\n",
            "To: /content/test.activities.yml\n",
            "\r  0% 0.00/14.3k [00:00<?, ?B/s]\r100% 14.3k/14.3k [00:00<00:00, 61.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tqV3caohYxF",
        "outputId": "918d38f7-4bd9-4eaa-9519-f5db9f17e510"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 31M\n",
            "drwxr-xr-x 1 root root 4.0K Jun 23 01:15 sample_data\n",
            "-rw-r--r-- 1 root root  14K Jun 23 18:46 test.activities.yml\n",
            "-rw-r--r-- 1 root root 8.2M Jun 23 18:46 test.geom.yml\n",
            "-rw-r--r-- 1 root root  10M Jun 23 18:46 test.mp4\n",
            "-rw-r--r-- 1 root root  12M Jun 23 18:46 test.regions.yml\n",
            "-rw-r--r-- 1 root root 2.7K Jun 23 18:46 test.types.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get bounding boxes, classes and track ids for detections in the first frame\n",
        "import yaml\n",
        "\n",
        "file_path = 'test.geom.yml'\n",
        "with open(file_path, 'r') as file:\n",
        "    geom = yaml.safe_load(file)\n",
        "file_path = 'test.types.yml'\n",
        "with open(file_path, 'r') as file:\n",
        "    types = yaml.safe_load(file)"
      ],
      "metadata": {
        "id": "ssfyfJ_GhqJw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Ground Truth DataFrame"
      ],
      "metadata": {
        "id": "AhVEW7Fq0FjR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AS pd.DataFrame </br>\n",
        "format: </br>\n",
        "{idx: geom_id0, </br>\n",
        "track_id: geom_id1, </br>\n",
        "label: types_cset3-key_on_id1, </br>\n",
        "conf: types_cset3-value_on_id1, </br>\n",
        "frame: geom_ts0, </br>\n",
        "xmin: geom_g0.split(' ')[0], ymin: geom_g0.split(' ')[1], xmax: geom_g0.split(' ')[2], ymax: geom_g0.split(' ')[3]}"
      ],
      "metadata": {
        "id": "zmiSOfvLl4mX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# helper function to get gt labels and confidence from types\n",
        "\n",
        "def get_labels_conf(types, frame_num):\n",
        "  # returns lists: labels, conf\n",
        "  labels = []\n",
        "  conf = []\n",
        "  for i in types:\n",
        "    try:\n",
        "      if (i['types']['id1'] in track_id):\n",
        "          label, conf = next(iter(i['types']['cset3'].items()))\n",
        "          labels.append(label)\n",
        "          conf.appens(conf)\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "  return labels, conf"
      ],
      "metadata": {
        "id": "Id6F8IBAuWdr"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a ground truth dataframe, gtdf\n",
        "\n",
        "detections = []\n",
        "frame_num = 0\n",
        "\n",
        "# sample of geom with detections by frame_num\n",
        "for i in geom:\n",
        "  try:\n",
        "    if (i['geom']['ts0'] == frame_num):\n",
        "      detections.append(i)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "# parse data from detections\n",
        "idx = [i['geom']['id0'] for i in detections]\n",
        "track_id = [i['geom']['id1'] for i in detections]\n",
        "label, conf = get_labels_conf(types, frame_num)\n",
        "frame = [i['geom']['ts0'] for i in detections]\n",
        "xmin, ymin, xmax, ymax = [], [], [], []\n",
        "for i in detections:\n",
        "  bb = i['geom']['g0'].split(' ')\n",
        "  xmin.append(bb[0])\n",
        "  ymin.append(bb[1])\n",
        "  xmax.append(bb[2])\n",
        "  ymax.append(bb[3])\n",
        "\n",
        "gt = {'idx': idx, 'track_id': track_id, 'label': label, 'conf': conf, 'frame': frame, 'xmin': xmin, 'ymin': ymin, 'xmax': xmax, 'ymax': ymax}\n",
        "gtdf = pd.DataFrame(gt)\n",
        "gtdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "aT-VnF35l4ca",
        "outputId": "8e934abe-a80e-4ec5-c541-b7ac5c9e3c5f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      idx  track_id          label  conf  frame  xmin ymin  xmax ymax\n",
              "0       0         1        Vehicle   1.0      0   946  327  1010  360\n",
              "1    7243         2        Vehicle   1.0      0   648  495   801  559\n",
              "2   14486         3        Vehicle   1.0      0   114  375   237  419\n",
              "3   21729         4        Vehicle   1.0      0   102  349   212  386\n",
              "4   28972         5        Vehicle   1.0      0   902  659  1023  718\n",
              "5   34911        33         Person   1.0      0   281  517   320  577\n",
              "6   39594        34         Person   1.0      0   730  392   756  437\n",
              "7   46239        35         Person   1.0      0  1149  644  1185  714\n",
              "8   51025      5000  Parking_Meter   1.0      0  1056  368  1070  402\n",
              "9   58268      5001       Dumpster   1.0      0    69  291   117  328\n",
              "10  65511      5025           Tree   1.0      0     0  470   226  719\n",
              "11  72754      5030           Door   1.0      0    72  423    95  487"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-249c03f3-9e1a-4d9b-a05e-c4c3e741dac1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idx</th>\n",
              "      <th>track_id</th>\n",
              "      <th>label</th>\n",
              "      <th>conf</th>\n",
              "      <th>frame</th>\n",
              "      <th>xmin</th>\n",
              "      <th>ymin</th>\n",
              "      <th>xmax</th>\n",
              "      <th>ymax</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Vehicle</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>946</td>\n",
              "      <td>327</td>\n",
              "      <td>1010</td>\n",
              "      <td>360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7243</td>\n",
              "      <td>2</td>\n",
              "      <td>Vehicle</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>648</td>\n",
              "      <td>495</td>\n",
              "      <td>801</td>\n",
              "      <td>559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14486</td>\n",
              "      <td>3</td>\n",
              "      <td>Vehicle</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>114</td>\n",
              "      <td>375</td>\n",
              "      <td>237</td>\n",
              "      <td>419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>21729</td>\n",
              "      <td>4</td>\n",
              "      <td>Vehicle</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>102</td>\n",
              "      <td>349</td>\n",
              "      <td>212</td>\n",
              "      <td>386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28972</td>\n",
              "      <td>5</td>\n",
              "      <td>Vehicle</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>902</td>\n",
              "      <td>659</td>\n",
              "      <td>1023</td>\n",
              "      <td>718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>34911</td>\n",
              "      <td>33</td>\n",
              "      <td>Person</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>281</td>\n",
              "      <td>517</td>\n",
              "      <td>320</td>\n",
              "      <td>577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>39594</td>\n",
              "      <td>34</td>\n",
              "      <td>Person</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>730</td>\n",
              "      <td>392</td>\n",
              "      <td>756</td>\n",
              "      <td>437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>46239</td>\n",
              "      <td>35</td>\n",
              "      <td>Person</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1149</td>\n",
              "      <td>644</td>\n",
              "      <td>1185</td>\n",
              "      <td>714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>51025</td>\n",
              "      <td>5000</td>\n",
              "      <td>Parking_Meter</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1056</td>\n",
              "      <td>368</td>\n",
              "      <td>1070</td>\n",
              "      <td>402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>58268</td>\n",
              "      <td>5001</td>\n",
              "      <td>Dumpster</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>69</td>\n",
              "      <td>291</td>\n",
              "      <td>117</td>\n",
              "      <td>328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>65511</td>\n",
              "      <td>5025</td>\n",
              "      <td>Tree</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>470</td>\n",
              "      <td>226</td>\n",
              "      <td>719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>72754</td>\n",
              "      <td>5030</td>\n",
              "      <td>Door</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>72</td>\n",
              "      <td>423</td>\n",
              "      <td>95</td>\n",
              "      <td>487</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-249c03f3-9e1a-4d9b-a05e-c4c3e741dac1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-249c03f3-9e1a-4d9b-a05e-c4c3e741dac1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-249c03f3-9e1a-4d9b-a05e-c4c3e741dac1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AS LIST:\n",
        "format: [[xmin, ymin, xmax, ymax, track_id, class], ... ]"
      ],
      "metadata": {
        "id": "vky-9LoBrNbZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ISSUE BELOW:\n",
        "labels are not being parsed correctly... getting a lot of '-1's"
      ],
      "metadata": {
        "id": "Is9DvYP73-UX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frame_num = 0\n",
        "frame_1_detections = []\n",
        "all_labels = []\n",
        "all_detections_with_labels = []\n",
        "\n",
        "# bounding boxes and track ids\n",
        "for i in geom:\n",
        "  try:\n",
        "    if (i['geom']['ts0'] == frame_num):\n",
        "      frame_1_detections.append(i)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "# classes\n",
        "for j in range(len(frame_1_detections)):\n",
        "  for k in types:\n",
        "    try:\n",
        "      if frame_1_detections[j]['geom']['id1'] == k['types']['id1']:\n",
        "        all_labels.append(k)\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "# create list of detection objects [[xmin, ymin, xmax, ymax, track_id, class], ... ]\n",
        "for i in range(len(frame_1_detections)):\n",
        "  xmin, ymin, xmax, ymax = frame_1_detections[i]['geom']['g0'].split(' ')\n",
        "  track_id = frame_1_detections[i]['geom']['id1']\n",
        "  class_label = -1\n",
        "\n",
        "  for j in range(len(all_labels)):\n",
        "    class_str = ''\n",
        "    if track_id == all_labels[j]['types']['id1']:\n",
        "      class_str = list(all_labels[j]['types']['cset3'].keys())[0]\n",
        "\n",
        "    if class_str == 'Vehicle':\n",
        "      class_label = 2\n",
        "    elif class_str == 'Person':\n",
        "      class_label = 0\n",
        "    elif class_str == 'Bike':\n",
        "      class_label = 1\n",
        "\n",
        "  this_detection = [xmin, ymin, xmax, ymax, track_id, class_label]\n",
        "  all_detections_with_labels.append(this_detection)\n",
        "\n",
        "all_detections_with_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kT5lvCqqskT",
        "outputId": "3d690f63-f58f-4c03-8de1-bcd073f12240"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['946', '327', '1010', '360', 1, 2],\n",
              " ['648', '495', '801', '559', 2, 2],\n",
              " ['114', '375', '237', '419', 3, 2],\n",
              " ['102', '349', '212', '386', 4, 2],\n",
              " ['902', '659', '1023', '718', 5, 2],\n",
              " ['281', '517', '320', '577', 33, 0],\n",
              " ['730', '392', '756', '437', 34, 0],\n",
              " ['1149', '644', '1185', '714', 35, 0],\n",
              " ['1056', '368', '1070', '402', 5000, -1],\n",
              " ['69', '291', '117', '328', 5001, -1],\n",
              " ['0', '470', '226', '719', 5025, -1],\n",
              " ['72', '423', '95', '487', 5030, -1]]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "frame_1_detections[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6Zcy2GJyXSW",
        "outputId": "c1cdcd62-2ad5-4ef0-e487-f1914605d391"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'geom': {'id1': 1,\n",
              "  'id0': 0,\n",
              "  'ts0': 0,\n",
              "  'ts1': 0,\n",
              "  'g0': '946 327 1010 360',\n",
              "  'src': 'truth'}}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_labels[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVZZ8TTfyatu",
        "outputId": "bb4bd6dc-3827-4f57-bc4a-63debec7f733"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'types': {'id1': 1, 'cset3': {'Vehicle': 1.0}}}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "key, val = next(iter(all_labels[0]['types']['cset3'].items()))\n",
        "key"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "0mpIEud9w8i4",
        "outputId": "7456a7fd-7499-4184-f387-bf6e86259b0e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Vehicle'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "key = list(all_labels[0]['types']['cset3'].keys())[0]\n",
        "key"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Z3ZbYeg_x0VN",
        "outputId": "33cf54b7-35f4-4c89-d244-d6f883e88b1f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Vehicle'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_full = []\n",
        "for i in types:\n",
        "  try:\n",
        "    if frame_1_detections[0]['geom']['id1'] == i['types']['id1']:\n",
        "      labels_full.append(i)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "labels_full"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeBSx0NKuW52",
        "outputId": "ecce8192-1ace-4459-be17-e5ee3039ccd6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'types': {'id1': 1, 'cset3': {'Vehicle': 1.0}}}]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Thirdly, get inference from YOLOv8 with ByteTracker on this test clip"
      ],
      "metadata": {
        "id": "g4e9GxBThkD9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install YOLOv8"
      ],
      "metadata": {
        "id": "XNazmDKlh71f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install ultralytics\n",
        "!pip -q install lap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzXujc97hfeJ",
        "outputId": "a14fd4fe-96a1-4589-d4e9-5d6724cdb973"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for lap (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import lap\n",
        "\n",
        "model = YOLO('yolov8n.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aj8jAI5LiAq7",
        "outputId": "31ed7d03-29bc-41a5-fe19-cbbc53448b00"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to yolov8n.pt...\n",
            "100%|██████████| 6.23M/6.23M [00:00<00:00, 69.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.track(source='/content/test.mp4', conf=0.12, iou=0.5,\n",
        "                      device=0, save_txt=True, imgsz=1280, classes=[0,1,2],\n",
        "                      tracker=\"bytetrack.yaml\", stream=True)\n",
        "list_results = list(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joo7Vg7JiG8A",
        "outputId": "aed927d5-1525-4a7b-8d25-31f2de70bfa3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "video 1/1 (1/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 62.9ms\n",
            "video 1/1 (2/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 13.4ms\n",
            "video 1/1 (3/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 13.4ms\n",
            "video 1/1 (4/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 13.4ms\n",
            "video 1/1 (5/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 13.3ms\n",
            "video 1/1 (6/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 13.4ms\n",
            "video 1/1 (7/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 13.3ms\n",
            "video 1/1 (8/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 12.8ms\n",
            "video 1/1 (9/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 12.8ms\n",
            "video 1/1 (10/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 12.9ms\n",
            "video 1/1 (11/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 12.8ms\n",
            "video 1/1 (12/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 12.9ms\n",
            "video 1/1 (13/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 12.8ms\n",
            "video 1/1 (14/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 12.8ms\n",
            "video 1/1 (15/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 11.2ms\n",
            "video 1/1 (16/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 11.3ms\n",
            "video 1/1 (17/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 11.2ms\n",
            "video 1/1 (18/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 11.2ms\n",
            "video 1/1 (19/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 11.2ms\n",
            "video 1/1 (20/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 11.3ms\n",
            "video 1/1 (21/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 11.6ms\n",
            "video 1/1 (22/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 11.1ms\n",
            "video 1/1 (23/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 10.4ms\n",
            "video 1/1 (24/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 10.4ms\n",
            "video 1/1 (25/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 10.3ms\n",
            "video 1/1 (26/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 13.2ms\n",
            "video 1/1 (27/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 10.3ms\n",
            "video 1/1 (28/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 10.4ms\n",
            "video 1/1 (29/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 10.4ms\n",
            "video 1/1 (30/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 10.2ms\n",
            "video 1/1 (31/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 10.2ms\n",
            "video 1/1 (32/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 10.3ms\n",
            "video 1/1 (33/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 10.2ms\n",
            "video 1/1 (34/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 10.2ms\n",
            "video 1/1 (35/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 10.2ms\n",
            "video 1/1 (36/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 10.2ms\n",
            "video 1/1 (37/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 10.2ms\n",
            "video 1/1 (38/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 9.6ms\n",
            "video 1/1 (39/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 9.6ms\n",
            "video 1/1 (40/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 9.6ms\n",
            "video 1/1 (41/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 9.6ms\n",
            "video 1/1 (42/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 9.6ms\n",
            "video 1/1 (43/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 9.6ms\n",
            "video 1/1 (44/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 9.6ms\n",
            "video 1/1 (45/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 9.6ms\n",
            "video 1/1 (46/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 9.4ms\n",
            "video 1/1 (47/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 9.4ms\n",
            "video 1/1 (48/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 9.4ms\n",
            "video 1/1 (49/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 9.4ms\n",
            "video 1/1 (50/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 9.4ms\n",
            "video 1/1 (51/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 9.5ms\n",
            "video 1/1 (52/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 9.4ms\n",
            "video 1/1 (53/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 9.4ms\n",
            "video 1/1 (54/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 9.4ms\n",
            "video 1/1 (55/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 9.4ms\n",
            "video 1/1 (56/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 9.4ms\n",
            "video 1/1 (57/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 9.4ms\n",
            "video 1/1 (58/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 9.4ms\n",
            "video 1/1 (59/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 9.4ms\n",
            "video 1/1 (60/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 9.6ms\n",
            "video 1/1 (61/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 9.4ms\n",
            "video 1/1 (62/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 9.5ms\n",
            "video 1/1 (63/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 10.2ms\n",
            "video 1/1 (64/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 9.4ms\n",
            "video 1/1 (65/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.4ms\n",
            "video 1/1 (66/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.9ms\n",
            "video 1/1 (67/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.5ms\n",
            "video 1/1 (68/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.3ms\n",
            "video 1/1 (69/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.0ms\n",
            "video 1/1 (70/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.4ms\n",
            "video 1/1 (71/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.5ms\n",
            "video 1/1 (72/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 9.4ms\n",
            "video 1/1 (73/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 12.0ms\n",
            "video 1/1 (74/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 9.8ms\n",
            "video 1/1 (75/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 9.4ms\n",
            "video 1/1 (76/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 10.2ms\n",
            "video 1/1 (77/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 9.4ms\n",
            "video 1/1 (78/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.6ms\n",
            "video 1/1 (79/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.4ms\n",
            "video 1/1 (80/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.8ms\n",
            "video 1/1 (81/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.4ms\n",
            "video 1/1 (82/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.5ms\n",
            "video 1/1 (83/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.4ms\n",
            "video 1/1 (84/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.4ms\n",
            "video 1/1 (85/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.4ms\n",
            "video 1/1 (86/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 11.3ms\n",
            "video 1/1 (87/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.4ms\n",
            "video 1/1 (88/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.4ms\n",
            "video 1/1 (89/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 9.5ms\n",
            "video 1/1 (90/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 9.4ms\n",
            "video 1/1 (91/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 9.4ms\n",
            "video 1/1 (92/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 9.4ms\n",
            "video 1/1 (93/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 9.4ms\n",
            "video 1/1 (94/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 9.5ms\n",
            "video 1/1 (95/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 9.4ms\n",
            "video 1/1 (96/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 9.4ms\n",
            "video 1/1 (97/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 9.6ms\n",
            "video 1/1 (98/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 9.4ms\n",
            "video 1/1 (99/300) /content/test.mp4: 736x1280 3 persons, 5 cars, 9.5ms\n",
            "video 1/1 (100/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.4ms\n",
            "video 1/1 (101/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.4ms\n",
            "video 1/1 (102/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.5ms\n",
            "video 1/1 (103/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.5ms\n",
            "video 1/1 (104/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.5ms\n",
            "video 1/1 (105/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 11.6ms\n",
            "video 1/1 (106/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.4ms\n",
            "video 1/1 (107/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.4ms\n",
            "video 1/1 (108/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.4ms\n",
            "video 1/1 (109/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.1ms\n",
            "video 1/1 (110/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.1ms\n",
            "video 1/1 (111/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.1ms\n",
            "video 1/1 (112/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.1ms\n",
            "video 1/1 (113/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.1ms\n",
            "video 1/1 (114/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.1ms\n",
            "video 1/1 (115/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.1ms\n",
            "video 1/1 (116/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.2ms\n",
            "video 1/1 (117/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.1ms\n",
            "video 1/1 (118/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.1ms\n",
            "video 1/1 (119/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.1ms\n",
            "video 1/1 (120/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.1ms\n",
            "video 1/1 (121/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.1ms\n",
            "video 1/1 (122/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.2ms\n",
            "video 1/1 (123/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.2ms\n",
            "video 1/1 (124/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.2ms\n",
            "video 1/1 (125/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.2ms\n",
            "video 1/1 (126/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.2ms\n",
            "video 1/1 (127/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.2ms\n",
            "video 1/1 (128/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 12.8ms\n",
            "video 1/1 (129/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.6ms\n",
            "video 1/1 (130/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.4ms\n",
            "video 1/1 (131/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.4ms\n",
            "video 1/1 (132/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 11.3ms\n",
            "video 1/1 (133/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 11.5ms\n",
            "video 1/1 (134/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 14.3ms\n",
            "video 1/1 (135/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.6ms\n",
            "video 1/1 (136/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.5ms\n",
            "video 1/1 (137/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.4ms\n",
            "video 1/1 (138/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 11.3ms\n",
            "video 1/1 (139/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.4ms\n",
            "video 1/1 (140/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.4ms\n",
            "video 1/1 (141/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.5ms\n",
            "video 1/1 (142/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.5ms\n",
            "video 1/1 (143/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.5ms\n",
            "video 1/1 (144/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.7ms\n",
            "video 1/1 (145/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 11.3ms\n",
            "video 1/1 (146/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 11.4ms\n",
            "video 1/1 (147/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.8ms\n",
            "video 1/1 (148/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 14.6ms\n",
            "video 1/1 (149/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.5ms\n",
            "video 1/1 (150/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.5ms\n",
            "video 1/1 (151/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.5ms\n",
            "video 1/1 (152/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.5ms\n",
            "video 1/1 (153/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.5ms\n",
            "video 1/1 (154/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.6ms\n",
            "video 1/1 (155/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.6ms\n",
            "video 1/1 (156/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.6ms\n",
            "video 1/1 (157/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.6ms\n",
            "video 1/1 (158/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.7ms\n",
            "video 1/1 (159/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.6ms\n",
            "video 1/1 (160/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.6ms\n",
            "video 1/1 (161/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.7ms\n",
            "video 1/1 (162/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.8ms\n",
            "video 1/1 (163/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.7ms\n",
            "video 1/1 (164/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.4ms\n",
            "video 1/1 (165/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.8ms\n",
            "video 1/1 (166/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.7ms\n",
            "video 1/1 (167/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.1ms\n",
            "video 1/1 (168/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.8ms\n",
            "video 1/1 (169/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.8ms\n",
            "video 1/1 (170/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.5ms\n",
            "video 1/1 (171/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.5ms\n",
            "video 1/1 (172/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.6ms\n",
            "video 1/1 (173/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.5ms\n",
            "video 1/1 (174/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.5ms\n",
            "video 1/1 (175/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.5ms\n",
            "video 1/1 (176/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.6ms\n",
            "video 1/1 (177/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.5ms\n",
            "video 1/1 (178/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.4ms\n",
            "video 1/1 (179/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.9ms\n",
            "video 1/1 (180/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.5ms\n",
            "video 1/1 (181/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.5ms\n",
            "video 1/1 (182/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.5ms\n",
            "video 1/1 (183/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.5ms\n",
            "video 1/1 (184/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.4ms\n",
            "video 1/1 (185/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.4ms\n",
            "video 1/1 (186/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.4ms\n",
            "video 1/1 (187/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.4ms\n",
            "video 1/1 (188/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.4ms\n",
            "video 1/1 (189/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.5ms\n",
            "video 1/1 (190/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.4ms\n",
            "video 1/1 (191/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.8ms\n",
            "video 1/1 (192/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.4ms\n",
            "video 1/1 (193/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.5ms\n",
            "video 1/1 (194/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.4ms\n",
            "video 1/1 (195/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.4ms\n",
            "video 1/1 (196/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.5ms\n",
            "video 1/1 (197/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.4ms\n",
            "video 1/1 (198/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.4ms\n",
            "video 1/1 (199/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.9ms\n",
            "video 1/1 (200/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.4ms\n",
            "video 1/1 (201/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.4ms\n",
            "video 1/1 (202/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.9ms\n",
            "video 1/1 (203/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.3ms\n",
            "video 1/1 (204/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.9ms\n",
            "video 1/1 (205/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.9ms\n",
            "video 1/1 (206/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.7ms\n",
            "video 1/1 (207/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.7ms\n",
            "video 1/1 (208/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.7ms\n",
            "video 1/1 (209/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.7ms\n",
            "video 1/1 (210/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 17.8ms\n",
            "video 1/1 (211/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.7ms\n",
            "video 1/1 (212/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.8ms\n",
            "video 1/1 (213/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.8ms\n",
            "video 1/1 (214/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.7ms\n",
            "video 1/1 (215/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.7ms\n",
            "video 1/1 (216/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.7ms\n",
            "video 1/1 (217/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.7ms\n",
            "video 1/1 (218/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.8ms\n",
            "video 1/1 (219/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.8ms\n",
            "video 1/1 (220/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.8ms\n",
            "video 1/1 (221/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.7ms\n",
            "video 1/1 (222/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.8ms\n",
            "video 1/1 (223/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.7ms\n",
            "video 1/1 (224/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.7ms\n",
            "video 1/1 (225/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.7ms\n",
            "video 1/1 (226/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.9ms\n",
            "video 1/1 (227/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.7ms\n",
            "video 1/1 (228/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.8ms\n",
            "video 1/1 (229/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.7ms\n",
            "video 1/1 (230/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.7ms\n",
            "video 1/1 (231/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.7ms\n",
            "video 1/1 (232/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.7ms\n",
            "video 1/1 (233/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.2ms\n",
            "video 1/1 (234/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.8ms\n",
            "video 1/1 (235/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.8ms\n",
            "video 1/1 (236/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.7ms\n",
            "video 1/1 (237/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.7ms\n",
            "video 1/1 (238/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.7ms\n",
            "video 1/1 (239/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 10.1ms\n",
            "video 1/1 (240/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.7ms\n",
            "video 1/1 (241/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.7ms\n",
            "video 1/1 (242/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.8ms\n",
            "video 1/1 (243/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.8ms\n",
            "video 1/1 (244/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.8ms\n",
            "video 1/1 (245/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.6ms\n",
            "video 1/1 (246/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.7ms\n",
            "video 1/1 (247/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.7ms\n",
            "video 1/1 (248/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.0ms\n",
            "video 1/1 (249/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.7ms\n",
            "video 1/1 (250/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.7ms\n",
            "video 1/1 (251/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.6ms\n",
            "video 1/1 (252/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.7ms\n",
            "video 1/1 (253/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.8ms\n",
            "video 1/1 (254/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.8ms\n",
            "video 1/1 (255/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.7ms\n",
            "video 1/1 (256/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.7ms\n",
            "video 1/1 (257/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.7ms\n",
            "video 1/1 (258/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.7ms\n",
            "video 1/1 (259/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.7ms\n",
            "video 1/1 (260/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.8ms\n",
            "video 1/1 (261/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.8ms\n",
            "video 1/1 (262/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.8ms\n",
            "video 1/1 (263/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.7ms\n",
            "video 1/1 (264/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.7ms\n",
            "video 1/1 (265/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.7ms\n",
            "video 1/1 (266/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.7ms\n",
            "video 1/1 (267/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.7ms\n",
            "video 1/1 (268/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.8ms\n",
            "video 1/1 (269/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.7ms\n",
            "video 1/1 (270/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.8ms\n",
            "video 1/1 (271/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.7ms\n",
            "video 1/1 (272/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.6ms\n",
            "video 1/1 (273/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.7ms\n",
            "video 1/1 (274/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.9ms\n",
            "video 1/1 (275/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.1ms\n",
            "video 1/1 (276/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.1ms\n",
            "video 1/1 (277/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.1ms\n",
            "video 1/1 (278/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.0ms\n",
            "video 1/1 (279/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.9ms\n",
            "video 1/1 (280/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.8ms\n",
            "video 1/1 (281/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.9ms\n",
            "video 1/1 (282/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.9ms\n",
            "video 1/1 (283/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.9ms\n",
            "video 1/1 (284/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.8ms\n",
            "video 1/1 (285/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.8ms\n",
            "video 1/1 (286/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.0ms\n",
            "video 1/1 (287/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.9ms\n",
            "video 1/1 (288/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.9ms\n",
            "video 1/1 (289/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.9ms\n",
            "video 1/1 (290/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.8ms\n",
            "video 1/1 (291/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.9ms\n",
            "video 1/1 (292/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.9ms\n",
            "video 1/1 (293/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.4ms\n",
            "video 1/1 (294/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.9ms\n",
            "video 1/1 (295/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.9ms\n",
            "video 1/1 (296/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.9ms\n",
            "video 1/1 (297/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 8.9ms\n",
            "video 1/1 (298/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.0ms\n",
            "video 1/1 (299/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.1ms\n",
            "video 1/1 (300/300) /content/test.mp4: 736x1280 3 persons, 4 cars, 9.1ms\n",
            "Speed: 4.8ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n",
            "Results saved to \u001b[1mruns/detect/track\u001b[0m\n",
            "300 labels saved to runs/detect/track/labels\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# frame 1 detections as .txt file(s)\n",
        "!cat runs/detect/track/labels/test_1.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkOx3gC2iS2J",
        "outputId": "487fe4b7-d9cb-4b61-b15f-259b52fb66ee"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 0.137419 0.553092 0.0945308 0.0548357 1\n",
            "2 0.763876 0.478838 0.0469688 0.0366087 2\n",
            "2 0.123751 0.511463 0.0826546 0.044233 3\n",
            "2 0.567661 0.733765 0.111929 0.0792986 4\n",
            "0 0.232489 0.761387 0.019395 0.080564 5\n",
            "0 0.581185 0.575837 0.0138645 0.05707 6\n",
            "2 0.751597 0.962718 0.090546 0.0741219 7\n",
            "0 0.909582 0.944357 0.0208885 0.095949 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ".txt files format ^\n",
        "- [class, xmid, ymid, w, h, track_id]</br></br>"
      ],
      "metadata": {
        "id": "nlVxMugtkXLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# frame 1 detection as tensor objects\n",
        "list_results[0].boxes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBDrMZrJjQz1",
        "outputId": "71d765a0-01e6-472d-b53b-92e4081de149"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING ⚠️ 'Boxes.boxes' is deprecated. Use 'Boxes.data' instead.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ultralytics.yolo.engine.results.Boxes object with attributes:\n",
              "\n",
              "boxes: tensor([[1.1540e+02, 3.7849e+02, 2.3640e+02, 4.1797e+02, 1.0000e+00, 8.8784e-01, 2.0000e+00],\n",
              "        [9.4770e+02, 3.3158e+02, 1.0078e+03, 3.5794e+02, 2.0000e+00, 8.5510e-01, 2.0000e+00],\n",
              "        [1.0550e+02, 3.5233e+02, 2.1130e+02, 3.8418e+02, 3.0000e+00, 8.5349e-01, 2.0000e+00],\n",
              "        [6.5497e+02, 4.9976e+02, 7.9824e+02, 5.5686e+02, 4.0000e+00, 8.5208e-01, 2.0000e+00],\n",
              "        [2.8517e+02, 5.1920e+02, 3.1000e+02, 5.7720e+02, 5.0000e+00, 8.3465e-01, 0.0000e+00],\n",
              "        [7.3504e+02, 3.9406e+02, 7.5279e+02, 4.3515e+02, 6.0000e+00, 7.6037e-01, 0.0000e+00],\n",
              "        [9.0410e+02, 6.6647e+02, 1.0200e+03, 7.1984e+02, 7.0000e+00, 7.5590e-01, 2.0000e+00],\n",
              "        [1.1509e+03, 6.4540e+02, 1.1776e+03, 7.1448e+02, 8.0000e+00, 6.6577e-01, 0.0000e+00]])\n",
              "cls: tensor([2., 2., 2., 2., 0., 0., 2., 0.])\n",
              "conf: tensor([0.8878, 0.8551, 0.8535, 0.8521, 0.8347, 0.7604, 0.7559, 0.6658])\n",
              "data: tensor([[1.1540e+02, 3.7849e+02, 2.3640e+02, 4.1797e+02, 1.0000e+00, 8.8784e-01, 2.0000e+00],\n",
              "        [9.4770e+02, 3.3158e+02, 1.0078e+03, 3.5794e+02, 2.0000e+00, 8.5510e-01, 2.0000e+00],\n",
              "        [1.0550e+02, 3.5233e+02, 2.1130e+02, 3.8418e+02, 3.0000e+00, 8.5349e-01, 2.0000e+00],\n",
              "        [6.5497e+02, 4.9976e+02, 7.9824e+02, 5.5686e+02, 4.0000e+00, 8.5208e-01, 2.0000e+00],\n",
              "        [2.8517e+02, 5.1920e+02, 3.1000e+02, 5.7720e+02, 5.0000e+00, 8.3465e-01, 0.0000e+00],\n",
              "        [7.3504e+02, 3.9406e+02, 7.5279e+02, 4.3515e+02, 6.0000e+00, 7.6037e-01, 0.0000e+00],\n",
              "        [9.0410e+02, 6.6647e+02, 1.0200e+03, 7.1984e+02, 7.0000e+00, 7.5590e-01, 2.0000e+00],\n",
              "        [1.1509e+03, 6.4540e+02, 1.1776e+03, 7.1448e+02, 8.0000e+00, 6.6577e-01, 0.0000e+00]])\n",
              "id: tensor([1., 2., 3., 4., 5., 6., 7., 8.])\n",
              "is_track: True\n",
              "orig_shape: (720, 1280)\n",
              "shape: torch.Size([8, 7])\n",
              "xywh: tensor([[ 175.8964,  398.2260,  120.9994,   39.4817],\n",
              "        [ 977.7612,  344.7637,   60.1201,   26.3583],\n",
              "        [ 158.4019,  368.2531,  105.7979,   31.8478],\n",
              "        [ 726.6056,  528.3107,  143.2695,   57.0950],\n",
              "        [ 297.5856,  548.1984,   24.8256,   58.0061],\n",
              "        [ 743.9169,  414.6028,   17.7466,   41.0904],\n",
              "        [ 962.0447,  693.1568,  115.8989,   53.3678],\n",
              "        [1164.2654,  679.9373,   26.7373,   69.0833]])\n",
              "xywhn: tensor([[0.1374, 0.5531, 0.0945, 0.0548],\n",
              "        [0.7639, 0.4788, 0.0470, 0.0366],\n",
              "        [0.1238, 0.5115, 0.0827, 0.0442],\n",
              "        [0.5677, 0.7338, 0.1119, 0.0793],\n",
              "        [0.2325, 0.7614, 0.0194, 0.0806],\n",
              "        [0.5812, 0.5758, 0.0139, 0.0571],\n",
              "        [0.7516, 0.9627, 0.0905, 0.0741],\n",
              "        [0.9096, 0.9444, 0.0209, 0.0959]])\n",
              "xyxy: tensor([[ 115.3967,  378.4852,  236.3961,  417.9669],\n",
              "        [ 947.7012,  331.5845, 1007.8213,  357.9428],\n",
              "        [ 105.5029,  352.3292,  211.3009,  384.1770],\n",
              "        [ 654.9708,  499.7632,  798.2404,  556.8582],\n",
              "        [ 285.1728,  519.1953,  309.9984,  577.2014],\n",
              "        [ 735.0436,  394.0576,  752.7902,  435.1480],\n",
              "        [ 904.0953,  666.4729, 1019.9942,  719.8407],\n",
              "        [1150.8967,  645.3957, 1177.6340,  714.4789]])\n",
              "xyxyn: tensor([[0.0902, 0.5257, 0.1847, 0.5805],\n",
              "        [0.7404, 0.4605, 0.7874, 0.4971],\n",
              "        [0.0824, 0.4893, 0.1651, 0.5336],\n",
              "        [0.5117, 0.6941, 0.6236, 0.7734],\n",
              "        [0.2228, 0.7211, 0.2422, 0.8017],\n",
              "        [0.5743, 0.5473, 0.5881, 0.6044],\n",
              "        [0.7063, 0.9257, 0.7969, 0.9998],\n",
              "        [0.8991, 0.8964, 0.9200, 0.9923]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ultralytics.yolo.engine.results.Boxes attribute formats ^:\n",
        "- Boxes.boxes, Boxes.data use [xmin, ymin, xmax, ymax, track_id, conf, class]\n",
        "- xywh, xywhn use [xmid, ymid, w, h]\n",
        "- xyxy, xyxyn use [xmin, ymin, xmax, ymax]"
      ],
      "metadata": {
        "id": "-V4r6xRjkgNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list_results[0].boxes.data[0][6]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rc1x09x4kL-M",
        "outputId": "179dd503-2a52-4d03-9a1e-7ea5a08fa19e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IfmGZVRklL5P"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "e558uTSrpL9I"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}